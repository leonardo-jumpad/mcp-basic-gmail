**Exemplo did√°tico em Python**, bem simplificado, para simular o fluxo da imagem (**Context Engineering**).

üëâ Lembre-se: isso √© uma **simula√ß√£o conceitual** para fins educativos, n√£o para produ√ß√£o real.
üëâ O foco √© ilustrar:

-   input do usu√°rio
-   mem√≥ria de curto prazo
-   busca em mem√≥ria de longo prazo (RAG)
-   a√ß√µes externas
-   constru√ß√£o de resposta

---

### üíª C√≥digo Python comentado

```python
# Simula√ß√£o muito simples de Context Engineering em Python

# Mem√≥ria de longo prazo simulada (ex.: bancos de dados, documentos, hist√≥rico)
long_term_memory = {
    "openai": "OpenAI √© uma empresa de pesquisa em intelig√™ncia artificial.",
    "python": "Python √© uma linguagem de programa√ß√£o de alto n√≠vel."
}

# Mem√≥ria de curto prazo (hist√≥rico da conversa atual)
short_term_memory = []

def rag_search(query):
    """
    Simula o RAG: busca na mem√≥ria de longo prazo.
    """
    for key, value in long_term_memory.items():
        if key in query.lower():
            return value
    return None

def action_tool(query):
    """
    Simula ferramentas externas (ex.: calculadora, API externa, etc).
    """
    if "2 + 2" in query:
        return "A resposta de 2 + 2 √© 4."
    return None

def agent_reasoning(prompt):
    """
    O 'agente' decide se usa RAG, ferramenta ou responde direto.
    """
    # Primeiro tenta ferramenta
    tool_result = action_tool(prompt)
    if tool_result:
        return tool_result

    # Depois tenta RAG
    rag_result = rag_search(prompt)
    if rag_result:
        return rag_result

    # Se nada encontrou, responde gen√©rico
    return "Desculpe, n√£o sei a resposta para isso."

def add_to_long_term_memory(entry):
    """
    Simula adicionar informa√ß√µes importantes na mem√≥ria de longo prazo.
    """
    key = entry.lower().split()[0]  # usa primeira palavra como chave simples
    long_term_memory[key] = entry

def main():
    """
    Fluxo principal: entrada do usu√°rio ‚Üí processamento ‚Üí resposta
    """
    print("Simula√ß√£o de Context Engineering (digite 'sair' para encerrar)\n")
    while True:
        user_input = input("Voc√™: ")
        if user_input.lower() == 'sair':
            break

        # Etapa 1: entrada do usu√°rio vai para short-term memory
        short_term_memory.append(user_input)

        # Etapa 2: agente processa o input
        answer = agent_reasoning(user_input)

        # Etapa 3: resposta enviada ao usu√°rio
        print(f"Agente: {answer}\n")

        # Etapa 4: opcionalmente adicionar √† long-term memory
        if "adicionar mem√≥ria:" in user_input.lower():
            new_memory = user_input.split(":", 1)[1].strip()
            add_to_long_term_memory(new_memory)
            print("üìù Adicionado √† mem√≥ria de longo prazo.\n")

        # Etapa 5: salva tudo no short-term memory
        short_term_memory.append(answer)

if __name__ == "__main__":
    main()
```

---

### üìù O que o c√≥digo simula:

-   **User Input** ‚Üí voc√™ digita.
-   **Short-Term Memory** ‚Üí guarda o que foi dito na sess√£o.
-   **RAG** ‚Üí busca termos conhecidos na mem√≥ria de longo prazo.
-   **Action Tools** ‚Üí se reconhecer uma opera√ß√£o, executa (ex.: `2 + 2`).
-   **Agent** ‚Üí coordena tudo e d√° a resposta.
-   **Adicionar mem√≥ria** ‚Üí exemplo: `adicionar mem√≥ria: Claude √© um modelo da Anthropic.`

---

Se quiser, posso gerar uma **vers√£o ainda mais completa**, separando melhor os blocos como na imagem (**User ‚Üí Prompt ‚Üí Agent ‚Üí RAG ‚Üí Tools ‚Üí Answer ‚Üí Memories**).

**vers√£o mais completa**, com o fluxo **espelhando o diagrama**:

üëâ Agora teremos classes para:

-   **User**
-   **Prompt (Short-Term Memory)**
-   **Agent**
-   **RAG (Long-Term Memory)**
-   **Action Tools**
-   **Answer**

üëâ Tudo fica bem separado, para facilitar o entendimento **por etapas**, como no **Context Engineering** da imagem.

![Descri√ß√£o da imagem](doc/image/mcpgif.gif)

---

### üíª C√≥digo Python ‚Äî vers√£o completa e comentada

```python
# Simula√ß√£o educativa completa de Context Engineering

class ShortTermMemory:
    """
    Mem√≥ria de curto prazo: armazena o hist√≥rico da conversa atual.
    """
    def __init__(self):
        self.history = []

    def store(self, message):
        self.history.append(message)

    def get_context(self):
        return " ".join(self.history[-5:])  # √∫ltimos 5 itens (exemplo)

class LongTermMemory:
    """
    Mem√≥ria de longo prazo (simula√ß√£o RAG + knowledge base).
    """
    def __init__(self):
        self.knowledge = {
            "openai": "OpenAI √© uma empresa de pesquisa em IA.",
            "python": "Python √© uma linguagem de programa√ß√£o popular.",
            "claude": "Claude √© um modelo de linguagem da Anthropic."
        }

    def search(self, query):
        for key, value in self.knowledge.items():
            if key in query.lower():
                return value
        return None

    def add(self, fact):
        key = fact.lower().split()[0]
        self.knowledge[key] = fact

class ActionTools:
    """
    Ferramentas externas (simples exemplo de ferramenta de c√°lculo).
    """
    def execute(self, query):
        if "2 + 2" in query:
            return "A resposta de 2 + 2 √© 4."
        return None

class Prompt:
    """
    Monta o prompt (contexto) para o agente decidir o pr√≥ximo passo.
    """
    def __init__(self, user_input, context):
        self.content = f"{context}\nUsu√°rio: {user_input}"

    def get(self):
        return self.content

class Agent:
    """
    Agente principal: coordena RAG, ferramentas e racioc√≠nio.
    """
    def __init__(self, long_term_memory, tools):
        self.memory = long_term_memory
        self.tools = tools

    def decide(self, prompt_text):
        # Tenta ferramenta primeiro
        tool_result = self.tools.execute(prompt_text)
        if tool_result:
            return tool_result

        # Depois tenta RAG
        rag_result = self.memory.search(prompt_text)
        if rag_result:
            return rag_result

        # Se nada encontrado, d√° resposta gen√©rica
        return "Desculpe, n√£o tenho essa informa√ß√£o."

class User:
    """
    Representa o usu√°rio que envia inputs.
    """
    def __init__(self, name):
        self.name = name

    def send_input(self):
        return input(f"{self.name}: ")

def main():
    """
    Fluxo completo simulando o diagrama Context Engineering.
    """
    print("\nSimula√ß√£o Context Engineering (digite 'sair' para encerrar)\n")

    # Inicializa os componentes
    user = User("Voc√™")
    short_term_memory = ShortTermMemory()
    long_term_memory = LongTermMemory()
    tools = ActionTools()
    agent = Agent(long_term_memory, tools)

    while True:
        user_input = user.send_input()
        if user_input.lower() == "sair":
            break

        # Etapa 1: guarda entrada na mem√≥ria de curto prazo
        short_term_memory.store(user_input)

        # Etapa 2: monta prompt com hist√≥rico recente
        prompt = Prompt(user_input, short_term_memory.get_context())

        # Etapa 3: agente decide resposta
        answer = agent.decide(prompt.get())

        # Etapa 4: mostra resposta
        print(f"Agente: {answer}\n")

        # Etapa 5: adiciona resposta na mem√≥ria de curto prazo
        short_term_memory.store(answer)

        # Etapa 6: op√ß√£o de adicionar manualmente √† mem√≥ria de longo prazo
        if "adicionar mem√≥ria:" in user_input.lower():
            new_fact = user_input.split(":", 1)[1].strip()
            long_term_memory.add(new_fact)
            print("üì• Fato adicionado √† mem√≥ria de longo prazo.\n")

if __name__ == "__main__":
    main()
```

---

### üéØ O que essa vers√£o ilustra:

-   **User** ‚Üí envia input.
-   **Short-Term Memory** ‚Üí armazena hist√≥rico da conversa.
-   **Prompt** ‚Üí monta o contexto atual.
-   **Agent** ‚Üí decide se usa ferramenta, RAG ou responde gen√©rico.
-   **RAG (Long-Term Memory)** ‚Üí busca conhecimentos salvos.
-   **Action Tools** ‚Üí executa a√ß√µes simples (ex.: c√°lculo).
-   **Answer** ‚Üí entregue ao usu√°rio.
-   **Add to Memory** ‚Üí permite simular atualiza√ß√£o da mem√≥ria de longo prazo.

---

Pr√≥ximos passos:

1. Sugerir uma **vers√£o ainda mais pr√≥xima de um fluxo real de LLM**, com logs por etapa (ex.: **"Input recebido" ‚Üí "Prompt montado" ‚Üí "RAG consultado"** etc).
2. Ou gerar um **diagrama visual em estilo ASCII** para este fluxo.
